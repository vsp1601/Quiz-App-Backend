# Fashion Recommendation API

A sophisticated machine learning-powered fashion recommendation system built with FastAPI, featuring personalized recommendations, user authentication, and intelligent product matching.

## ğŸš€ Features

- **Personalized Recommendations**: ML-powered recommendation engine that learns from user preferences
- **User Authentication**: Secure JWT-based authentication system
- **Product Management**: Comprehensive product catalog with filtering and search
- **User Preferences**: Track and store user preferences for better recommendations
- **Image Processing**: Support for product images with automatic feature extraction
- **RESTful API**: Clean, well-documented REST API endpoints
- **Database Support**: SQLite (default) and PostgreSQL support
- **Docker Ready**: Containerized deployment with Docker and Docker Compose
- **Caching**: Redis integration for improved performance

## ğŸ—ï¸ Architecture

```
Backend/
â”œâ”€â”€ app/                    # Main application
â”‚   â”œâ”€â”€ main.py            # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â””â”€â”€ database.py        # Database connection and session management
â”œâ”€â”€ api/                   # API endpoints
â”‚   â”œâ”€â”€ auth.py            # Authentication endpoints
â”‚   â”œâ”€â”€ products.py        # Product management endpoints
â”‚   â”œâ”€â”€ recommendations.py # Recommendation engine endpoints
â”‚   â””â”€â”€ user_preferences.py # User preference management
â”œâ”€â”€ models/                # Data models and ML engine
â”‚   â”œâ”€â”€ database_models.py # SQLAlchemy database models
â”‚   â””â”€â”€ recommendation_engine.py # ML recommendation engine
â”œâ”€â”€ services/              # Business logic services
â”‚   â”œâ”€â”€ data_processor.py  # Data processing utilities
â”‚   â”œâ”€â”€ feature_extractor.py # Feature extraction for ML
â”‚   â””â”€â”€ model_trainer.py   # Model training utilities
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ models/           # Trained ML models
â”‚   â””â”€â”€ processed/        # Processed datasets
â”œâ”€â”€ images/               # Product images
â””â”€â”€ tests/               # Test files
```

## ğŸ› ï¸ Tech Stack

- **Backend Framework**: FastAPI
- **Database**: SQLite (default)
- **ORM**: SQLAlchemy
- **Authentication**: JWT with PassLib
- **Machine Learning**: scikit-learn, pandas, numpy
- **Image Processing**: OpenCV, Pillow
- **Caching**: Redis
- **Containerization**: Docker, Docker Compose
- **API Documentation**: Swagger UI

## ğŸ“‹ Prerequisites

- Python 3.11+
- pip (Python package manager)
- Docker & Docker Compose (optional)
- PostgreSQL (if not using SQLite)

## ğŸš€ Quick Start

### Option 1: Using Docker (Recommended)

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Backend
   ```

2. **Start with Docker Compose**
   ```bash
   docker-compose up --build
   ```

   This will start:
   - FastAPI application on `http://localhost:8000`
   - PostgreSQL database on port 5432
   - Redis cache on port 6379

### Option 2: Local Development

1. **Clone and navigate to the repository**
   ```bash
   git clone <repository-url>
   cd Backend
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Setup environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

5. **Initialize the database**
   ```bash
   python quick_start.py
   ```

6. **Load sample data (if available)**
   ```bash
   python simple_data_loader.py
   ```

7. **Start the development server**
   ```bash
   uvicorn app.main:app --reload
   ```

## ğŸ“Š Data Setup

### Using the Quick Start Script

The `quick_start.py` script will:
- Create necessary directories
- Set up environment configuration
- Initialize the database
- Create a data loader script

### Loading Your Dataset

1. Place your fashion dataset (Excel/CSV) in the root directory
2. Place product images in the `./images/` directory
3. Run the data loader:
   ```bash
   python simple_data_loader.py
   ```

### Expected Dataset Format

Your dataset should include columns:
- `id`: Unique product identifier
- `gender`: Product gender (Men/Women/Boys/Girls)
- `masterCategory`: Main category
- `subCategory`: Sub-category
- `articleType`: Type of article
- `baseColour`: Primary color
- `season`: Season (Summer/Winter/Fall/Spring)
- `year`: Year of production
- `usage`: Usage type
- `productDisplayName`: Product name

## ğŸ”— API Endpoints

### Authentication
- `POST /api/v1/auth/register` - User registration
- `POST /api/v1/auth/login` - User login

### Products
- `GET /api/v1/products/` - List products with filtering
- `GET /api/v1/products/random` - Get random products
- `GET /api/v1/products/{product_id}` - Get specific product

### Recommendations
- `GET /api/v1/recommendations/recommendations` - Personalized recommendations
- `GET /api/v1/recommendations/popular` - Popular products
- `POST /api/v1/recommendations/retrain-model` - Retrain ML model

### User Preferences
- `GET /api/v1/preferences/` - Get user preferences
- `POST /api/v1/preferences/` - Set user preferences

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file with the following variables:

```env
# Database
DATABASE_URL=sqlite:///./fashion_db.sqlite
# For PostgreSQL: postgresql://user:password@localhost:5432/fashion_db

# Redis
REDIS_URL=redis://localhost:6379

# JWT
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# File Paths
IMAGES_PATH=./images
DATA_PATH=./data
MODELS_PATH=./data/models

# ML Settings
MIN_RATINGS_FOR_TRAINING=10
RECOMMENDATION_COUNT=20
```

## ğŸ¤– Machine Learning Features

### Recommendation Engine

The system uses a sophisticated ML pipeline:

1. **Feature Extraction**: Extracts color and style features from product images
2. **User Profiling**: Builds user profiles based on rating history
3. **Collaborative Filtering**: Uses user-item interactions for recommendations
4. **Content-Based Filtering**: Considers product attributes and features
5. **Hybrid Approach**: Combines multiple recommendation strategies

### Model Training

- Automatic model training when sufficient data is available
- Retrain endpoint for manual model updates
- Fallback to popular items for cold-start users
- Feature scaling and normalization

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
python -m pytest tests/

# Run with coverage
python -m pytest tests/ --cov=app --cov=api --cov=models
```

## ğŸ“ˆ Performance

- **Caching**: Redis integration for improved response times
- **Database Optimization**: Efficient queries with proper indexing
- **Batch Processing**: Batch feature extraction and model predictions
- **Lazy Loading**: On-demand model loading and training

## ğŸ³ Docker Deployment

### Production Deployment

1. **Build the image**
   ```bash
   docker build -t fashion-recommendation-api .
   ```

2. **Run with Docker Compose**
   ```bash
   docker-compose -f docker-compose.prod.yml up -d
   ```

### Development with Docker

```bash
# Start all services
docker-compose up

# Start specific service
docker-compose up app

# View logs
docker-compose logs -f app
```

## ğŸ“š API Documentation

Once the server is running, visit:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ”’ Security

- JWT-based authentication
- Password hashing with bcrypt
- CORS configuration
- Input validation with Pydantic
- SQL injection protection with SQLAlchemy


### Scaling Considerations

- Use PostgreSQL for production
- Implement Redis clustering for high availability
- Consider horizontal scaling with load balancers
- Use CDN for image serving

## ğŸ”® Future Enhancements

- [ ] Real-time recommendations with WebSockets
- [ ] Advanced ML models (Deep Learning)
- [ ] Advanced analytics dashboard


